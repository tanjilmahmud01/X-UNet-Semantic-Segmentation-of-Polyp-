{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\ntf.test.gpu_device_name()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-20T03:56:33.552579Z","iopub.execute_input":"2022-06-20T03:56:33.553309Z","iopub.status.idle":"2022-06-20T03:56:35.744572Z","shell.execute_reply.started":"2022-06-20T03:56:33.553207Z","shell.execute_reply":"2022-06-20T03:56:35.743682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#libraries\nimport os\nimport random\n\nimport numpy as np\nimport cv2\nfrom glob import glob\nfrom scipy.ndimage.interpolation import rotate\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-06-20T03:56:35.746193Z","iopub.execute_input":"2022-06-20T03:56:35.747177Z","iopub.status.idle":"2022-06-20T03:56:36.02236Z","shell.execute_reply.started":"2022-06-20T03:56:35.747139Z","shell.execute_reply":"2022-06-20T03:56:36.021297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Process Image Part -1\n# Read and Save Image\ndef read_image(imagefile, grayscale=False):\n    if grayscale == True:\n        image = cv2.imread(imagefile)\n        #image = np.expand_dims(image, -1)\n    else:\n        image = cv2.imread(imagefile)\n    return image\n\ndef save_image(image, mask, path, binary=True):\n    image = np.array(image)\n    if binary == True:\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n    cv2.imwrite(path[0], image)\n    cv2.imwrite(path[1], mask)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T03:56:37.489312Z","iopub.execute_input":"2022-06-20T03:56:37.490392Z","iopub.status.idle":"2022-06-20T03:56:37.497828Z","shell.execute_reply.started":"2022-06-20T03:56:37.490345Z","shell.execute_reply":"2022-06-20T03:56:37.497058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Process Image Part -2\n# Data Augmentation\ndef concat_images(images, rows, cols):\n    _, h, w, _ = images.shape\n    images = images.reshape((rows, cols, h, w, 3))\n    images = images.transpose(0, 2, 1, 3, 4)\n    images = images.reshape((rows * h, cols * w, 3))\n    return images\n\ndef check_size(size):\n    if type(size) == int:\n        size = (size, size)\n    if type(size) != tuple:\n        raise TypeError('size is int or tuple')\n    return size\n\ndef subtract(image):\n    image = image / 255\n    return image\n\ndef resize(image, size):\n    size = check_size(size)\n    image = cv2.resize(image, size)\n    return image\n\ndef center_crop(image, mask, crop_size, size):\n    h, w, _ = image.shape\n    crop_size = check_size(crop_size)\n    top = (h - crop_size[0]) // 2 \n    left = (w - crop_size[1]) // 2 \n    bottom = top + crop_size[0]\n    right = left + crop_size[1]\n\n    image = image[top:bottom, left:right, :]\n    mask = mask[top:bottom, left:right, :]\n\n    image = resize(image, size)\n    mask = resize(mask, size)\n\n    return image, mask\n\ndef random_crop(image, mask, crop_size, size):\n    crop_size = check_size(crop_size)\n    h, w, _ = image.shape\n    top = np.random.randint(0, h - crop_size[0])\n    left = np.random.randint(0, w - crop_size[1])\n    bottom = top + crop_size[0]\n    right = left + crop_size[1]\n\n    image = image[top:bottom, left:right, :]\n    mask = mask[top:bottom, left:right, :]\n\n    image = resize(image, size)\n    mask = resize(mask, size)\n\n    return image, mask\n\ndef horizontal_flip(image, mask, size):\n    image = image[:, ::-1, :]\n    mask = mask[:, ::-1, :]\n\n    image = resize(image, size)\n    mask = resize(mask, size)\n\n    return image, mask\n\ndef vertical_flip(image, mask, size):\n    image = image[::-1, :, :]\n    mask = mask[::-1, :, :]\n\n    image = resize(image, size)\n    mask = resize(mask, size)\n\n    return image, mask\n\ndef scale_augmentation(image, mask, scale_range, crop_size, size):\n    scale_size = np.random.randint(*scale_range)\n    image = cv2.resize(image, (scale_size, scale_size))\n    mask = cv2.resize(mask, (scale_size, scale_size))\n    image, mask = random_crop(image, mask, crop_size, size)\n    return image, mask\n\ndef random_rotation(image, mask, size, angle_range=(0, 90)):\n    h1, w1, _ = image.shape\n    h2, w2, _ = mask.shape\n\n    angle = np.random.randint(*angle_range)\n    image = rotate(image, angle)\n    image = resize(image, (h1, w1))\n\n    mask = rotate(mask, angle)\n    mask = resize(mask, (h2, w2))\n\n    image = resize(image, size)\n    mask = resize(mask, size)\n\n    return image, mask\n\ndef cutout(image_origin, mask_origin, mask_size, mask_value='mean'):\n    image = np.copy(image_origin)\n    mask = np.copy(mask_origin)\n\n    if mask_value == 'mean':\n        mask_value = image.mean()\n    elif mask_value == 'random':\n        mask_value = np.random.randint(0, 256)\n\n    h, w, _ = image.shape\n    top = np.random.randint(0 - mask_size // 2, h - mask_size)\n    left = np.random.randint(0 - mask_size // 2, w - mask_size)\n    bottom = top + mask_size\n    right = left + mask_size\n    if top < 0:\n        top = 0\n    if left < 0:\n        left = 0\n\n    image[top:bottom, left:right, :].fill(mask_value)\n    mask[top:bottom, left:right, :].fill(0)\n\n    image = resize(image, size)\n    mask = resize(mask, size)\n\n    return image, mask\n\ndef brightness_augment(img, mask, factor=0.5):\n    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV) #convert to hsv\n    hsv = np.array(hsv, dtype=np.float64)\n    hsv[:, :, 2] = hsv[:, :, 2] * (factor + np.random.uniform()) #scale channel V uniformly\n    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255 #reset out of range values\n    rgb = cv2.cvtColor(np.array(hsv, dtype=np.uint8), cv2.COLOR_HSV2RGB)\n\n    image = resize(rgb, size)\n    mask = resize(mask, size)\n\n    return image, mask\n\ndef rgb_to_grayscale(img, mask):\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    img = [img, img, img]\n    img = np.transpose(img, (1, 2, 0))\n\n    image = resize(img, size)\n    mask = resize(mask, size)\n    return image, mask ","metadata":{"execution":{"iopub.status.busy":"2022-06-20T03:56:38.607191Z","iopub.execute_input":"2022-06-20T03:56:38.60786Z","iopub.status.idle":"2022-06-20T03:56:38.639719Z","shell.execute_reply.started":"2022-06-20T03:56:38.607823Z","shell.execute_reply":"2022-06-20T03:56:38.638812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dir(name):\n    try:\n        os.mkdir(name)\n    except:\n        pass","metadata":{"execution":{"iopub.status.busy":"2022-06-20T03:56:39.625434Z","iopub.execute_input":"2022-06-20T03:56:39.626096Z","iopub.status.idle":"2022-06-20T03:56:39.630429Z","shell.execute_reply.started":"2022-06-20T03:56:39.626059Z","shell.execute_reply":"2022-06-20T03:56:39.629378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Process Image Part - 3\n\"\"\"\ntrain, val, test set creation,\nand save those images in a folder named 'new_data'\n\"\"\"\nif __name__ == '__main__':\n    ### Image Augmentation\n    size = (256, 256)\n    crop_size = (300, 300)\n\n    path = \"../input/kvasir\"\n    dataset_name = \"kvasir_segmentation_dataset\"\n    full_path = os.path.join(path, dataset_name)\n\n    new_path = \"./\"\n    create_dir(new_path)\n    new_full_path = os.path.join(new_path, dataset_name)\n\n    train_path = os.path.join(new_full_path, \"train\")\n    valid_path = os.path.join(new_full_path, \"valid\")\n    test_path = os.path.join(new_full_path, \"test\")\n\n    if not os.path.exists(new_full_path):\n        os.mkdir(new_full_path)\n        for path in [train_path, valid_path, test_path]:\n            os.mkdir(path)\n            os.mkdir(os.path.join(path, \"images\"))\n            os.mkdir(os.path.join(path, \"masks\"))\n\n    images = glob(os.path.join(full_path, \"images/\", \"*\"))\n    masks = glob(os.path.join(full_path, \"masks/\", \"*\"))\n\n    images.sort()\n    masks.sort()\n\n    len_ids = len(images)\n    train_size = int((80/100)*len_ids)\n    valid_size = int((10/100)*len_ids)\t\t## Here 10 is the percent of images used for validation\n    test_size = int((10/100)*len_ids)\t\t## Here 10 is the percent of images used for testing\n\n    train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)\n    train_masks, test_masks = train_test_split(masks, test_size=test_size, random_state=42)\n\n    train_images, valid_images = train_test_split(train_images, test_size=test_size, random_state=42)\n    train_masks, valid_masks = train_test_split(train_masks, test_size=test_size, random_state=42)\n\n    print(\"Total Size: \", len_ids)\n    print(\"Training Size: \", train_size)\n    print(\"Validation Size: \", valid_size)\n    print(\"Testing Size: \", test_size)\n\n    ## testing images and masks\n    for idx, p in tqdm(enumerate(test_images), total=len(test_images)):\n        ## Path\n        name = p.split(\"/\")[-1].split(\".\")[0]\n        image_path = test_images[idx]\n        mask_path = test_masks[idx]\n\n        if os.path.exists(image_path) and os.path.exists(mask_path):\n            image = read_image(image_path)\n            mask = read_image(mask_path, grayscale=True)\n\n            new_image_path = os.path.join(new_full_path, \"test\", \"images/\")\n            new_mask_path = os.path.join(new_full_path, \"test\", \"masks/\")\n\n            image = resize(image, size)\n            mask = resize(mask, size)\n\n            img_path = new_image_path + str(name) + \".jpg\"\n            mask_path = new_mask_path + str(name) + \".jpg\"\n            tmp_path = [img_path, mask_path]\n            save_image(image, mask, tmp_path)\n\n    ## Validation images and masks\n    for idx, p in tqdm(enumerate(valid_images), total=len(valid_images)):\n        ## Path\n        name = p.split(\"/\")[-1].split(\".\")[0]\n        image_path = valid_images[idx]\n        mask_path = valid_masks[idx]\n\n        if os.path.exists(image_path) and os.path.exists(mask_path):\n            image = read_image(image_path)\n            mask = read_image(mask_path, grayscale=True)\n\n            new_image_path = os.path.join(new_full_path, \"valid\", \"images/\")\n            new_mask_path = os.path.join(new_full_path, \"valid\", \"masks/\")\n\n            image = resize(image, size)\n            mask = resize(mask, size)\n\n            img_path = new_image_path + str(name) + \".jpg\"\n            mask_path = new_mask_path + str(name) + \".jpg\"\n            tmp_path = [img_path, mask_path]\n            save_image(image, mask, tmp_path)\n\n    ## Training images and masks\n    for idx, p in tqdm(enumerate(train_images), total=len(train_images)):\n        ## Path\n        name = p.split(\"/\")[-1].split(\".\")[0]\n        image_path = train_images[idx]\n        mask_path = train_masks[idx]\n\n        if os.path.exists(image_path) and os.path.exists(image_path):\n            image = read_image(image_path)\n            mask = read_image(mask_path, grayscale=True)\n\n            ## Augment\n            image1, mask1 = center_crop(image, mask, crop_size, size)\n            image2, mask2 = random_crop(image, mask, crop_size, size)\n            image3, mask3 = horizontal_flip(image, mask, size)\n            image4, mask4 = vertical_flip(image, mask, size)\n            image5, mask5 = scale_augmentation(image, mask, (512, 768), crop_size, size)\n            image6, mask6 = random_rotation(image, mask, size)\n            image7, mask7 = cutout(image, mask, 224)\n            ## Extra Cropping\n            image8, mask8 = random_crop(image, mask, crop_size, size)\n            ## Extra Scale Augmentation\n            image10, mask10 = scale_augmentation(image, mask, (540, 820), crop_size, size)\n            image11, mask11 = scale_augmentation(image, mask, (720, 1024), crop_size, size)\n            ## Extra Rotation\n            image12, mask12 = random_rotation(image, mask, size)\n            image13, mask13 = random_rotation(image, mask, size)\n            ## Brightness\n            image14, mask14 = brightness_augment(image, mask, factor=0.3)\n            image15, mask15 = brightness_augment(image, mask, factor=0.6)\n            image16, mask16 = brightness_augment(image, mask, factor=0.9)\n            ## More Rotation\n            #image17, mask17 = random_rotation(image, mask, size)\n            #image18, mask18 = random_rotation(image, mask, size)\n            ## More Random Crop\n            image19, mask19 = random_crop(image, mask, crop_size, size)\n            #image20, mask20 = random_crop(image, mask, crop_size, size)\n            ## More Cutout\n            image21, mask21 = cutout(image, mask, 224)\n            image22, mask22 = cutout(image, mask, 256)\n            ## Grayscale\n            image23, mask23 = rgb_to_grayscale(image, mask)\n            image24, mask24 = rgb_to_grayscale(image5, mask5)\n            image25, mask25 = rgb_to_grayscale(image15, mask15)\n            image26, mask26 = rgb_to_grayscale(image3, mask3)\n            image27, mask27 = rgb_to_grayscale(image4, mask4)\n            image28, mask28 = rgb_to_grayscale(image5, mask5)\n            image29, mask29 = rgb_to_grayscale(image15, mask15)\n            image30, mask30 = rgb_to_grayscale(image16, mask16)\n\n            ## Original image and mask\n            image = resize(image, size)\n            mask = resize(mask, size)\n\n            ## All images and masks\n            all_images = [image, image1, image2, image3, image4, image5, image6,image7, image8,\n                          image10, image11, image12, image13, image14, image15, image16, image19,\n                          image21, image22, image23, image24, image25, image26, image27, image28, image29, image30]\n            all_masks  = [mask, mask1, mask2, mask3, mask4, mask5, mask6, mask7, mask8,\n                          mask10 ,mask11, mask12, mask13, mask14, mask15, mask16, mask19, \n                          mask21, mask22, mask23, mask24, mask25, mask26, mask27, mask28, mask29, mask30]\n\n            ## Save the images and masks\n            new_image_path = os.path.join(new_full_path, \"train\", \"images/\")\n            new_mask_path = os.path.join(new_full_path, \"train\", \"masks/\")\n\n            for j in range(len(all_images)):\n                img_path = new_image_path + str(name) + \"_\" + str(j) + \".jpg\"\n                msk_path = new_mask_path + str(name) + \"_\" + str(j) + \".jpg\"\n\n                img = all_images[j]\n                msk = all_masks[j]\n                path = [img_path, msk_path]\n\n                save_image(img, msk, path)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:37:27.365011Z","iopub.execute_input":"2022-06-20T08:37:27.365515Z","iopub.status.idle":"2022-06-20T08:53:58.200328Z","shell.execute_reply.started":"2022-06-20T08:37:27.365471Z","shell.execute_reply":"2022-06-20T08:53:58.1994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put all images in the folder into a list (works)\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport glob\n# Put all images in the folder into a list (works)\nimages = []\nfor f in glob.iglob(\"./kvasir_segmentation_dataset/train/images/*\"):\n    images.append(np.asarray(Image.open(f)))\n\n# plot the images (works)\nimages = np.array(images)\nfig, axs = plt.subplots(15, 5, figsize=(10, 50))\nfig.subplots_adjust(hspace = .3, wspace=.3)\naxs = axs.ravel()\n\n# This is for displaying the names (works)\nfor filename in os.listdir('./kvasir_segmentation_dataset/train/images/'):\n  RatName = filename[:-4]\n\ni = 0\nfor filename in os.listdir('./kvasir_segmentation_dataset/train/images/'):\n  RatName = filename[:-4]\n  axs[i].imshow(images[i])\n  #axs[i].set_title(RatName)\n  i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put all images in the folder into a list (works)\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport glob\n# Put all images in the folder into a list (works)\nimages = []\nfor f in glob.iglob(\"./kvasir_segmentation_dataset/train/masks/*\"):\n    images.append(np.asarray(Image.open(f)))\n\n# plot the images (works)\nimages = np.array(images)\nfig, axs = plt.subplots(15, 5, figsize=(10, 50))\nfig.subplots_adjust(hspace = .3, wspace=.3)\naxs = axs.ravel()\n\n# This is for displaying the names (works)\nfor filename in os.listdir('./kvasir_segmentation_dataset/train/masks/'):\n  RatName = filename[:-4]\n\ni = 0\nfor filename in os.listdir('./kvasir_segmentation_dataset/train/masks/'):\n  RatName = filename[:-4]\n  axs[i].imshow(images[i])\n  #axs[i].set_title(RatName)\n  i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nData Generator\n\"\"\"\nimport os\nimport numpy as np\nimport cv2\nfrom tensorflow.keras.utils import Sequence\n\ndef parse_image(img_path, image_size):\n    image_rgb = cv2.imread(img_path, 1)\n    h, w, _ = image_rgb.shape\n    if (h == image_size) and (w == image_size):\n        pass\n    else:\n        image_rgb = cv2.resize(image_rgb, (image_size, image_size))\n    image_rgb = image_rgb/255.0\n    return image_rgb\n\ndef parse_mask(mask_path, image_size):\n    mask = cv2.imread(mask_path, -1)\n    h, w = mask.shape\n    if (h == image_size) and (w == image_size):\n        pass\n    else:\n        mask = cv2.resize(mask, (image_size, image_size))\n    mask = np.expand_dims(mask, -1)\n    mask = mask/255.0\n\n    return mask\n\nclass DataGen(Sequence):\n    def __init__(self, image_size, images_path, masks_path, batch_size=8):\n        self.image_size = image_size\n        self.images_path = images_path\n        self.masks_path = masks_path\n        self.batch_size = batch_size\n        self.on_epoch_end()\n\n    def __getitem__(self, index):\n        if(index+1)*self.batch_size > len(self.images_path):\n            self.batch_size = len(self.images_path) - index*self.batch_size\n\n        images_path = self.images_path[index*self.batch_size : (index+1)*self.batch_size]\n        masks_path = self.masks_path[index*self.batch_size : (index+1)*self.batch_size]\n\n        images_batch = []\n        masks_batch = []\n\n        for i in range(len(images_path)):\n            ## Read image and mask\n            image = parse_image(images_path[i], self.image_size)\n            mask = parse_mask(masks_path[i], self.image_size)\n\n            images_batch.append(image)\n            masks_batch.append(mask)\n\n        return np.array(images_batch), np.array(masks_batch)\n\n    def on_epoch_end(self):\n        pass\n\n    def __len__(self):\n        return int(np.ceil(len(self.images_path)/float(self.batch_size)))","metadata":{"execution":{"iopub.status.busy":"2022-06-20T04:16:31.465614Z","iopub.execute_input":"2022-06-20T04:16:31.466744Z","iopub.status.idle":"2022-06-20T04:16:31.892182Z","shell.execute_reply.started":"2022-06-20T04:16:31.466701Z","shell.execute_reply":"2022-06-20T04:16:31.891211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, ZeroPadding2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import Xception\n\ndef conv_block(input, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n \n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n \n    return x\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\ndef build_xception_unet(input_shape):\n    \"\"\" Input \"\"\"\n    inputs = Input(shape=(input_shape, input_shape, 3), name=\"input_image\")\n    xception = Xception(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n    s1 = xception.get_layer(\"input_image\").output         ## (256 x 256)\n    s2 = xception.get_layer(\"block1_conv1_act\").output         \n    s2 = ZeroPadding2D(( (1, 0), (1, 0) ))(s2)               ## (128 x 128)\n    s3 = xception.get_layer(\"block3_sepconv2_bn\").output\n    s3 = ZeroPadding2D(( (1, 0), (1, 0) ))(s3)                ## (56 x 56)\n    s4 = xception.get_layer(\"block4_sepconv2_bn\").output         ## (28 x 28)\n    \"\"\" Bridge \"\"\"\n    b1 = xception.get_layer(\"block13_sepconv2_bn\").output         ## (14 x 14)\n\n    d1 = decoder_block(b1, s4, 512)                     ## (28 x 28)\n    d2 = decoder_block(d1, s3, 256)                     ## (56 x 112)\n    d3 = decoder_block(d2, s2, 128)                     ## (128 x 128)\n    d4 = decoder_block(d3, s1, 64)                      ## (256 x 256)\n\n    \"\"\" Output \"\"\"\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n    model = Model(inputs, outputs, name=\"Xception_U-Net\")\n\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-20T10:43:04.76056Z","iopub.execute_input":"2022-06-20T10:43:04.761005Z","iopub.status.idle":"2022-06-20T10:43:11.454415Z","shell.execute_reply.started":"2022-06-20T10:43:04.760918Z","shell.execute_reply":"2022-06-20T10:43:11.453201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    input_shape = (224)\n    model = build_xception_unet(input_shape)\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T10:43:19.25656Z","iopub.execute_input":"2022-06-20T10:43:19.257264Z","iopub.status.idle":"2022-06-20T10:43:22.307095Z","shell.execute_reply.started":"2022-06-20T10:43:19.25723Z","shell.execute_reply":"2022-06-20T10:43:22.305976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nModel Matrics\n\"\"\"\nimport os\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\n\nsmooth = 1.\ndef dice_coef(y_true, y_pred):\n    y_true_f = tf.keras.layers.Flatten()(y_true)\n    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T04:16:31.920948Z","iopub.execute_input":"2022-06-20T04:16:31.921477Z","iopub.status.idle":"2022-06-20T04:16:31.933819Z","shell.execute_reply.started":"2022-06-20T04:16:31.921433Z","shell.execute_reply":"2022-06-20T04:16:31.9325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom glob import glob\nimport tensorflow as tf\nfrom tensorflow.keras.metrics import Precision, Recall, MeanIoU\nfrom tensorflow.keras.optimizers import Adam, Nadam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n\n# from data_generator import DataGen\n# from m_resunet import ResUnetPlusPlus\n# from metrics import dice_coef, dice_loss\n\nif __name__ == \"__main__\":\n    ## Path\n    file_path = \"./files/\"\n    model_path = \"./files/xception_unet.h5\"\n\n    ## Create files folder\n    try:\n        os.mkdir(\"./files\")\n    except:\n        pass\n\n    train_path = \"./kvasir_segmentation_dataset/train/\"\n    valid_path = \"./kvasir_segmentation_dataset/valid/\"\n\n    ## Training\n    train_image_paths = glob(os.path.join(train_path, \"images\", \"*\"))\n    train_mask_paths = glob(os.path.join(train_path, \"masks\", \"*\"))\n    train_image_paths.sort()\n    train_mask_paths.sort()\n\n    # train_image_paths = train_image_paths[:2000]\n    # train_mask_paths = train_mask_paths[:2000]\n\n    ## Validation\n    valid_image_paths = glob(os.path.join(valid_path, \"images\", \"*\"))\n    valid_mask_paths = glob(os.path.join(valid_path, \"masks\", \"*\"))\n    valid_image_paths.sort()\n    valid_mask_paths.sort()\n\n    ## Parameters\n    image_size = 256\n    batch_size = 8\n    lr = 1e-4\n    epochs = 50\n\n    train_steps = len(train_image_paths)//batch_size\n    valid_steps = len(valid_image_paths)//batch_size\n\n    ## Generator\n    train_gen = DataGen(image_size, train_image_paths, train_mask_paths, batch_size=batch_size)\n    valid_gen = DataGen(image_size, valid_image_paths, valid_mask_paths, batch_size=batch_size)\n\n    ## Unet\n    #arch = Unet(input_size=image_size)\n    #model = arch.build_model()\n\n    ## Unet2\n    #arch = Unet()\n    model = build_xception_unet(image_size)\n\n    ## ResUnet\n    #arch = ResUnet(input_size=image_size)\n    #model = arch.build_model()\n\n    ## ResUnet++\n    #arch = ResUnetPlusPlus(input_size=image_size)\n    #model = arch.build_model()\n\n    # FCN8\n    #arch = FCN8(input_size=image_size)\n    # model = arch.build_model()\n\n    optimizer = Nadam(lr)\n    metrics = [\"acc\", Recall(), Precision(), dice_coef, MeanIoU(num_classes=2)]\n    model.compile(loss=dice_loss, optimizer=optimizer, metrics=metrics)\n\n    csv_logger = CSVLogger(f\"{file_path}xception_unet_{batch_size}.csv\", append=False)\n    checkpoint = ModelCheckpoint(model_path, verbose=1, save_best_only=True)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, verbose=1)\n    early_stopping = EarlyStopping(monitor='val_loss', patience=9, restore_best_weights=False)\n    callbacks = [csv_logger, checkpoint, reduce_lr, early_stopping]\n\n    history=model.fit(train_gen,\n            validation_data=valid_gen,\n            steps_per_epoch=train_steps,\n            validation_steps=valid_steps,\n            epochs=epochs,\n            callbacks=callbacks)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T04:16:31.936004Z","iopub.execute_input":"2022-06-20T04:16:31.936603Z","iopub.status.idle":"2022-06-20T08:23:38.131418Z","shell.execute_reply.started":"2022-06-20T04:16:31.936557Z","shell.execute_reply":"2022-06-20T08:23:38.130029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:27:53.147019Z","iopub.execute_input":"2022-06-20T08:27:53.147866Z","iopub.status.idle":"2022-06-20T08:27:53.359979Z","shell.execute_reply.started":"2022-06-20T08:27:53.14782Z","shell.execute_reply":"2022-06-20T08:27:53.359105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model acc')\nplt.ylabel('acc')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:25:05.8721Z","iopub.execute_input":"2022-06-20T08:25:05.87262Z","iopub.status.idle":"2022-06-20T08:25:06.177132Z","shell.execute_reply.started":"2022-06-20T08:25:05.872582Z","shell.execute_reply":"2022-06-20T08:25:06.176125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.utils import CustomObjectScope\n\ndef mask_to_3d(mask):\n    mask = np.squeeze(mask)\n    mask = [mask, mask, mask]\n    mask = np.transpose(mask, (1, 2, 0))\n    return mask\n\nif __name__ == \"__main__\":\n    model_path = \"./files/xception_unet.h5\"\n    save_path = \"./result\"\n    test_path = \"./kvasir_segmentation_dataset/test/\"\n\n    image_size = 224\n    batch_size = 1\n\n    test_image_paths = glob(os.path.join(test_path, \"images\", \"*\"))\n    test_mask_paths = glob(os.path.join(test_path, \"masks\", \"*\"))\n    test_image_paths.sort()\n    test_mask_paths.sort()\n\n    ## Create result folder\n    try:\n        os.mkdir(save_path)\n    except:\n        pass\n\n    ## Model\n    with CustomObjectScope({'dice_loss': dice_loss, 'dice_coef': dice_coef}):\n        model = load_model(model_path)\n\n    ## Test\n    print(\"Test Result: \")\n    test_steps = len(test_image_paths)//batch_size\n    test_gen = DataGen(image_size, test_image_paths, test_mask_paths, batch_size=batch_size)\n    model.evaluate_generator(test_gen, steps=test_steps, verbose=1)\n\n    ## Generating the result\n    for i, path in tqdm(enumerate(test_image_paths), total=len(test_image_paths)):\n        image = parse_image(test_image_paths[i], image_size)\n        mask = parse_mask(test_mask_paths[i], image_size)\n\n        predict_mask = model.predict(np.expand_dims(image, axis=0))[0]\n        predict_mask = (predict_mask > 0.5) * 255.0\n\n        sep_line = np.ones((image_size, 10, 3)) * 255.0\n\n        mask = mask_to_3d(mask)\n        predict_mask = mask_to_3d(predict_mask)\n\n        all_images = [image * 255.0, sep_line, mask * 255.0, sep_line, predict_mask]\n        cv2.imwrite(f\"{save_path}/{i}.png\", np.concatenate(all_images, axis=1))\n\n    print(\"Test image generation complete\")","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:55:05.135562Z","iopub.execute_input":"2022-06-20T08:55:05.136402Z","iopub.status.idle":"2022-06-20T08:55:08.372696Z","shell.execute_reply.started":"2022-06-20T08:55:05.136368Z","shell.execute_reply":"2022-06-20T08:55:08.371481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r ./result.zip ./result","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:28:41.582801Z","iopub.execute_input":"2022-06-20T08:28:41.583195Z","iopub.status.idle":"2022-06-20T08:28:42.384465Z","shell.execute_reply.started":"2022-06-20T08:28:41.58316Z","shell.execute_reply":"2022-06-20T08:28:42.383278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r ./files.zip ./files","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:29:09.894569Z","iopub.execute_input":"2022-06-20T08:29:09.894977Z","iopub.status.idle":"2022-06-20T08:29:28.785778Z","shell.execute_reply.started":"2022-06-20T08:29:09.894944Z","shell.execute_reply":"2022-06-20T08:29:28.78453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put all images in the folder into a list (works)\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport glob\n# Put all images in the folder into a list (works)\nimages = []\nfor f in glob.iglob(\"./result/*\"):\n    images.append(np.asarray(Image.open(f)))\n\n# plot the images (works)\nimages = np.array(images)\nfig, axs = plt.subplots(15, 3, figsize=(150, 150))\nfig.subplots_adjust(hspace = .3, wspace=.1)\naxs = axs.ravel()\n\n# This is for displaying the names (works)\nfor filename in os.listdir('./result/'):\n  RatName = filename[:-4]\n\ni = 0\nfor filename in os.listdir('./result/'):\n  RatName = filename[:-4]\n  axs[i].imshow(images[i])\n  #axs[i].set_title(RatName)\n  i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}